<font color=red><b>代码实例，PyTorch实现基于CNN的手写数字识别，希望对您有所帮助。

## 环境说明
>**操作系统：Windows 10** 
> \
> **CUDA 版本为: 10.0**
> \
> **cudnn 版本为: 7.6.5**
> \
> **Python 版本为：Python 3.6.13**	
> \
> **PyTorch 版本为：1.0.0**
> \
> **注意CUDA、cudnn、Python、PyTorch版本之间的匹配**


## 一、模型训练
### 1.1 导入相关依赖

```python
import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms
```

### 1.2 选择使用的硬件

```python
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
```
### 1.3 超参数配置

```python
num_epochs = 5  # 训练分支数量
num_classes = 10  # 分类数目
batch_size = 100  # 批量大小
learning_rate = 0.001  # 学习率
```

### 1.4 准备训练集和测试集

```python
# 获取训练集
train_dataset = torchvision.datasets.MNIST(root='./MNIST_data',
                                           train=True,
                                           transform=transforms.ToTensor(),
                                           download=False)
# 获取测试集
test_dataset = torchvision.datasets.MNIST(root='./MNIST_data',
                                          train=False,
                                          transform=transforms.ToTensor(),
                                          download=False)
# 加载训练集
train_loader = torch.utils.data.DataLoader(dataset=train_dataset,
                                           batch_size=batch_size,
                                           shuffle=True)
# 加载测试集
test_loader = torch.utils.data.DataLoader(dataset=test_dataset,
                                          batch_size=batch_size,
                                          shuffle=False)
```
### 1.5 模型创建

```python
class ConvNet(nn.Module):
    def __init__(self, num_classes=10):
        super(ConvNet, self).__init__()
        self.layer1 = nn.Sequential(
            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2),
            nn.BatchNorm2d(6),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2)
        )
        self.layer2 = nn.Sequential(
            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=2),
            nn.BatchNorm2d(16),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2)
        )
        self.fc = nn.Linear(7 * 7 * 16, num_classes)

    def forward(self, x):
        out = self.layer1(x)
        out = self.layer2(out)
        out = out.reshape(out.size(0), -1)
        out = self.fc(out)
        return out
```
### 1.6 模型评估指标

```python
criterion = nn.CrossEntropyLoss()  # 交叉熵损失函数
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  # Adam优化器
```
### 1.7 模型训练
```python
total_step = len(train_loader)  # 训练总步长
# 开始训练
for epoch in range(num_epochs):
    for i, (images, labels) in enumerate(train_loader):
        images = images.to(device)
        labels = labels.to(device)

        outputs = model(images)
        loss = criterion(outputs, labels)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        if (i + 1) % 100 == 0:
            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'
                    .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))
```
### 1.8 模型测试
```python
model.eval()
with torch.no_grad():
    correct = 0
    total = 0
    for images, labels in test_loader:
        images = images.to(device)
        labels = labels.to(device)
        outputs = model(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()
print('Test Accuracy of tne model on the 10000 test iamges: {} %'.format(100 * correct / total))

```
### 1.9 模型保存
```python
# 保存模型
torch.save(model.state_dict(), 'model.ckpt')
```

### 1.10 完整代码
```python
# =====-*- coding: utf-8 -*-=====
# @Time  : 2022/3/24 20:19
# @Author: AXYZdong
# @File  : PyTorchModel.py
# @IDE   : Pycharm
# ===============================
# 导入相关依赖
import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms

# 选择使用的硬件
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
# 超参数
num_epochs = 5
num_classes = 10
batch_size = 100
learning_rate = 0.001
# 获取训练集
train_dataset = torchvision.datasets.MNIST(root='./MNIST_data',
                                           train=True,
                                           transform=transforms.ToTensor(),
                                           download=False)
# 获取测试集
test_dataset = torchvision.datasets.MNIST(root='./MNIST_data',
                                          train=False,
                                          transform=transforms.ToTensor(),
                                          download=False)
# 加载训练集
train_loader = torch.utils.data.DataLoader(dataset=train_dataset,
                                           batch_size=batch_size,
                                           shuffle=True)
# 加载测试集
test_loader = torch.utils.data.DataLoader(dataset=test_dataset,
                                          batch_size=batch_size,
                                          shuffle=False)


# 创建一个模型类
class ConvNet(nn.Module):
    def __init__(self, num_classes=10):
        super(ConvNet, self).__init__()
        self.layer1 = nn.Sequential(
            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2),
            nn.BatchNorm2d(6),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2)
        )
        self.layer2 = nn.Sequential(
            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=2),
            nn.BatchNorm2d(16),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=2, stride=2)
        )
        self.fc = nn.Linear(7 * 7 * 16, num_classes)

    def forward(self, x):
        out = self.layer1(x)
        out = self.layer2(out)
        out = out.reshape(out.size(0), -1)
        out = self.fc(out)
        return out


def model_train():
    model = ConvNet(num_classes).to(device)  # ConvNet类实例化成一个对象

    criterion = nn.CrossEntropyLoss()  # 交叉熵损失函数
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  # Adam优化器

    total_step = len(train_loader)  # 训练总步长
    # 开始训练
    for epoch in range(num_epochs):
        for i, (images, labels) in enumerate(train_loader):
            images = images.to(device)
            labels = labels.to(device)

            outputs = model(images)
            loss = criterion(outputs, labels)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            if (i + 1) % 100 == 0:
                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'
                      .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))
    # 模型测试
    model.eval()
    with torch.no_grad():
        correct = 0
        total = 0
        for images, labels in test_loader:
            images = images.to(device)
            labels = labels.to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    print('Test Accuracy of tne model on the 10000 test iamges: {} %'.format(100 * correct / total))
    # 保存模型
    torch.save(model.state_dict(), 'model.ckpt')


if __name__ == "__main__":
    model_train()
```
运行结果：

```python
Epoch [1/5], Step [100/600], Loss: 0.3397
Epoch [1/5], Step [200/600], Loss: 0.2530
Epoch [1/5], Step [300/600], Loss: 0.0510
Epoch [1/5], Step [400/600], Loss: 0.1459
Epoch [1/5], Step [500/600], Loss: 0.0717
Epoch [1/5], Step [600/600], Loss: 0.0749
Epoch [2/5], Step [100/600], Loss: 0.0590
Epoch [2/5], Step [200/600], Loss: 0.0121
Epoch [2/5], Step [300/600], Loss: 0.1118
Epoch [2/5], Step [400/600], Loss: 0.1396
Epoch [2/5], Step [500/600], Loss: 0.0540
Epoch [2/5], Step [600/600], Loss: 0.0438
Epoch [3/5], Step [100/600], Loss: 0.0257
Epoch [3/5], Step [200/600], Loss: 0.0839
Epoch [3/5], Step [300/600], Loss: 0.0860
Epoch [3/5], Step [400/600], Loss: 0.0455
Epoch [3/5], Step [500/600], Loss: 0.0389
Epoch [3/5], Step [600/600], Loss: 0.0419
Epoch [4/5], Step [100/600], Loss: 0.0522
Epoch [4/5], Step [200/600], Loss: 0.0554
Epoch [4/5], Step [300/600], Loss: 0.0146
Epoch [4/5], Step [400/600], Loss: 0.1057
Epoch [4/5], Step [500/600], Loss: 0.0529
Epoch [4/5], Step [600/600], Loss: 0.0327
Epoch [5/5], Step [100/600], Loss: 0.0169
Epoch [5/5], Step [200/600], Loss: 0.0206
Epoch [5/5], Step [300/600], Loss: 0.0571
Epoch [5/5], Step [400/600], Loss: 0.1069
Epoch [5/5], Step [500/600], Loss: 0.0238
Epoch [5/5], Step [600/600], Loss: 0.0166
Test Accuracy of tne model on the 10000 test iamges: 98.71 %
```

运行后本地的当前目录下会有一个模型文件：
![在这里插入图片描述](https://img-blog.csdnimg.cn/356549ec09804bb5a6f287fc28e58a82.png)


## 二、本地手写数字识别
### 2.1 导入相关依赖

```python
import torch
import PyTorchModel
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image, ImageOps
```

### 2.2 硬件选择

```python
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
```

### 2.3 本地模型加载

```python
model = PyTorchModel.ConvNet().to(device)
model.load_state_dict(torch.load('model.ckpt'))
```
### 2.4 本地图片处理
```python
img = Image.open('./num-draft/' + image_name)  # 导入本地图片
img_gray = np.array(ImageOps.grayscale(img))  # 图片灰度化
img_inv = (255 - img_gray) / 255.0  # 转成白底黑字，以适应MNIST数据集中的数据(黑底白字)。再进行归一化处理
image = np.float32(img_inv.reshape((1, 28 * 28)))  # 转换成浮点型
image_array_2_tensor = torch.from_numpy(image.reshape(1, 1, 28, 28)).to(device)  # array转换成tensor
```

### 2.5 图像预测

```python
 # 预测
predict = model(image_array_2_tensor)
prediction = torch.max(predict.data, 1)
print('预测的图片是: ', image_name, 'AI判断的数字是{}'.format(prediction[1]))  # 打印预测结果
```

### 2.6 完整代码
```python
# =====-*- coding: utf-8 -*-=====
# @Time  : 2022/3/24 21:17
# @Author: AXYZdong
# @File  : dong-PyTorch-recognize.py
# @IDE   : Pycharm
# ===============================
import torch
import PyTorchModel
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image, ImageOps
# 硬件选择
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
# 本地模型加载
model = PyTorchModel.ConvNet().to(device)
model.load_state_dict(torch.load('model.ckpt'))

# 本地图片名称保存在imag_names的列表中
image_names = ['num0.png', 'num1.png', 'num2.png', 'num3.png', 'num4.png',
               'num5.png', 'num6.png', 'num7.png', 'num8.png', 'num9.png']

# 批量预测本地图片
for image_name in image_names:
    # 本地图片处理
    img = Image.open('./num-draft/' + image_name)  # 导入本地图片
    img_gray = np.array(ImageOps.grayscale(img))  # 图片灰度化
    img_inv = (255 - img_gray) / 255.0  # 转成白底黑字，以适应MNIST数据集中的数据(黑底白字)。再进行归一化处理
    image = np.float32(img_inv.reshape((1, 28 * 28)))
    image_array_2_tensor = torch.from_numpy(image.reshape(1, 1, 28, 28)).to(device)
    # print(type(image_array_2_tensor))

    # 预测
    predict = model(image_array_2_tensor)
    prediction = torch.max(predict.data, 1)
    print('预测的图片是: ', image_name, 'AI判断的数字是{}'.format(prediction[1]))  # 打印预测结果

    # 准备显示
    plt.subplot(2, 5, image_names.index(image_name) + 1)
    plt.imshow(Image.open('./num-draft/' + image_name))
    plt.yticks([])
    plt.title(f'predict:{prediction[1][0]}', color='blue')

# 展示图像
plt.text(0, 40, 'By AXYZdong')  # 水印
plt.show()

```

运行结果：

```python
预测的图片是:  num0.png AI判断的数字是tensor([0], device='cuda:0')
预测的图片是:  num1.png AI判断的数字是tensor([1], device='cuda:0')
预测的图片是:  num2.png AI判断的数字是tensor([2], device='cuda:0')
预测的图片是:  num3.png AI判断的数字是tensor([3], device='cuda:0')
预测的图片是:  num4.png AI判断的数字是tensor([4], device='cuda:0')
预测的图片是:  num5.png AI判断的数字是tensor([5], device='cuda:0')
预测的图片是:  num6.png AI判断的数字是tensor([6], device='cuda:0')
预测的图片是:  num7.png AI判断的数字是tensor([7], device='cuda:0')
预测的图片是:  num8.png AI判断的数字是tensor([8], device='cuda:0')
预测的图片是:  num9.png AI判断的数字是tensor([9], device='cuda:0')
```
<p align="center">▲ 窗口输出的打印信息</p>

![在这里插入图片描述](https://img-blog.csdnimg.cn/2f7b38bd172041d6ace0f1ebf218cf04.png#pic_center)
<p align="center">▲ 批量识别图像展示</p>

<center><strong>—— END ——</strong></center>

